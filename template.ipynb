{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'Lab 5: Sea-Level Rise'\n",
        "author: Kyle Olcott kto1\n",
        "date: '2024-02-16'\n",
        "format:\n",
        "  html: default\n",
        "  docx:\n",
        "    toc: true\n",
        "    fig-format: png\n",
        "    number-sections: true\n",
        "    code-line-numbers: true\n",
        "date-format: 'ddd., MMM. D'\n",
        "bibliography: references.bib\n",
        "---"
      ],
      "id": "03dd24b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup\n",
        "\n",
        "## The usual\n",
        "\n",
        "As always:\n",
        "\n",
        "1. Clone the lab repository to your computer\n",
        "1. Open the lab repository in VS Code\n",
        "1. Open the Julia REPL and activate, then instantiate, the lab environment\n",
        "1. Make sure you can render: `quarto render template.qmd` in the terminal.\n",
        "    - If you run into issues, try running `] build IJulia` in the Julia REPL (`]` enters the package manager).\n",
        "    - If you still have issues, try opening up `blankfile.py`. That should trigger VS Code to give you the option to install the Python extension, which you should do. Then you should be able to open a menu in the bottom right of your screen to select which Python installation you want VS Code to use.\n",
        "\n",
        "\n",
        "## Load packages\n"
      ],
      "id": "c35b5458"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "using CSV\n",
        "using DataFrames\n",
        "using DataFramesMeta\n",
        "using Distributions\n",
        "using Plots\n",
        "using StatsPlots\n",
        "using Unitful\n",
        "\n",
        "Plots.default(; margin=5Plots.mm)"
      ],
      "id": "8f00cda1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Local package\n"
      ],
      "id": "b4c9e371"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "using Revise\n",
        "using HouseElevation"
      ],
      "id": "82a1dc7d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "house = let\n",
        "    haz_fl_dept = CSV.read(\"data/haz_fl_dept.csv\", DataFrame) # read in the file\n",
        "    desc = \"Apartment, living area on one floor, Structure\"\n",
        "    row = @rsubset(haz_fl_dept, :Description == desc)[1, :] # select the row I want\n",
        "    area = 1033u\"ft^2\"\n",
        "    height_above_gauge = 4u\"ft\"\n",
        "    House(\n",
        "        row;\n",
        "        area=area,\n",
        "        height_above_gauge=height_above_gauge,\n",
        "        value_usd=316_298,\n",
        "    )\n",
        "end"
      ],
      "id": "30256e3e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Location\n",
        "This location is near Peir 12 in Galveston of 2016 Strand #8, Galveston, TX 77550, which is a small groundlevel apartment. Values for the square footage and value were sourced from Redfin. The depth damage curve is thus an apartment on one floor in Galveston.\n"
      ],
      "id": "20db8292"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "let\n",
        "    depths = uconvert.(u\"ft\", (-7.0u\"ft\"):(1.0u\"inch\"):(30.0u\"ft\"))\n",
        "    damages = house.ddf.(depths) ./ 100\n",
        "    damages_1000_usd = damages .* house.value_usd ./ 1000\n",
        "    scatter(\n",
        "        depths,\n",
        "        damages_1000_usd;\n",
        "        xlabel=\"Flood Depth\",\n",
        "        ylabel=\"Damage (Thousand USD)\",\n",
        "        label=\"$(house.description)\\n($(house.source))\",\n",
        "        legend=:bottomright,\n",
        "        size=(800, 400),\n",
        "        yformatter=:plain, # prevents scientific notation\n",
        "    )\n",
        "end"
      ],
      "id": "c932df07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "let\n",
        "    elevations = 0u\"ft\":0.25u\"ft\":14u\"ft\"\n",
        "    costs = [elevation_cost(house, eᵢ) for eᵢ in elevations]\n",
        "    scatter(\n",
        "        elevations,\n",
        "        costs ./ 1_000;\n",
        "        xlabel=\"Elevation\",\n",
        "        ylabel=\"Cost (Thousand USD)\",\n",
        "        label=\"$(house.description)\\n($(house.source))\",\n",
        "        legend=:bottomright,\n",
        "        size=(800, 400),\n",
        "        yformatter=:plain, # prevents scientific notation\n",
        "    )\n",
        "end"
      ],
      "id": "e4edb535",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "slr_scenarios = let\n",
        "    df = CSV.read(\"data/slr_oddo.csv\", DataFrame)\n",
        "    [Oddo17SLR(a, b, c, tstar, cstar) for (a, b, c, tstar, cstar) in eachrow(df)]\n",
        "end\n",
        "println(\"There are $(length(slr_scenarios)) parameter sets\")"
      ],
      "id": "e0250955",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "let\n",
        "    years = 1900:2150\n",
        "    p = plot(;\n",
        "        xlabel=\"Year\",\n",
        "        ylabel=\"Mean sea-level (ft)\\nwith respect to the year 2000\",\n",
        "        label=\"Oddo et al. (2017)\",\n",
        "        legend=false\n",
        "    )\n",
        "    for s in rand(slr_scenarios, 250)\n",
        "        plot!(p, years, s.(years); color=:lightgrey, alpha=0.5, linewidth=0.5)\n",
        "    end\n",
        "    p\n",
        "end"
      ],
      "id": "d6d59c8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Functions that samples storm surge projections and discount rates.\n"
      ],
      "id": "d2866cee"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "function draw_surge_distribution()\n",
        "    μ = rand(Normal(5, 1))\n",
        "    σ = rand(Exponential(1.5))\n",
        "    ξ = rand(Normal(0.1, 0.05))\n",
        "    GeneralizedExtremeValue(μ, σ, ξ)\n",
        "end"
      ],
      "id": "48981722",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "function draw_discount_rate()\n",
        "    return rand(Normal(0.1, 0.02))\n",
        "end"
      ],
      "id": "049ceff9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modeling Reasoning\n",
        "The discount rate is modeled after the S&P 500 which has an expected discount rate of 10%. This may flucuate from time to time by approximately 4%, so the standard deviation will be 2%, allowing for the majority of the normal distribution to be with +/- 4% of 10%. \n",
        "\n",
        "The surge/flood distribution is hypothetical and based on the deterministic distribution that has been used in previous labs.\n"
      ],
      "id": "3991ae9a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p = ModelParams(\n",
        "    house=house,\n",
        "    years=2024:2083\n",
        ")"
      ],
      "id": "b3d000c2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sow = SOW(\n",
        "    rand(slr_scenarios),\n",
        "    draw_surge_distribution(),\n",
        "    draw_discount_rate()\n",
        ")"
      ],
      "id": "c29fa1c8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "a = Action(5.0u\"ft\")"
      ],
      "id": "fb597f80",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "res = run_sim(a, sow, p)"
      ],
      "id": "681f2fa0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tempsows = [SOW(rand(slr_scenarios), draw_surge_distribution(), draw_discount_rate()) for _ in 1:10] # for 10 SOWs\n",
        "sows = []\n",
        "for i in 1:11\n",
        "append!(sows, tempsows)\n",
        "end\n",
        "\n",
        "n = 0\n",
        "actions = []\n",
        "while n < 11\n",
        "tempactions = [Action(n*1u\"ft\") for _ in 1:10] # these are all the same\n",
        "append!(actions, tempactions)\n",
        "n = n+1\n",
        "end\n",
        "\n",
        "results = [run_sim(a, s, p) for (a, s) in zip(actions, sows)]"
      ],
      "id": "8f5685ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = DataFrame(\n",
        "    npv=results,\n",
        "    Δh_ft=[a.Δh_ft for a in actions],\n",
        "    slr_a=[s.slr.a for s in sows],\n",
        "    slr_b=[s.slr.b for s in sows],\n",
        "    slr_c=[s.slr.c for s in sows],\n",
        "    slr_tstar=[s.slr.tstar for s in sows],\n",
        "    slr_cstar=[s.slr.cstar for s in sows],\n",
        "    surge_μ=[s.surge_dist.μ for s in sows],\n",
        "    surge_σ=[s.surge_dist.σ for s in sows],\n",
        "    surge_ξ=[s.surge_dist.ξ for s in sows],\n",
        "    discount_rate=[s.discount_rate for s in sows],\n",
        ")"
      ],
      "id": "6ae9c8ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "let\n",
        "    npv = results\n",
        "    elevated = [a.Δh_ft for a in actions]\n",
        "    scatter(\n",
        "        elevated,\n",
        "        npv;\n",
        "        xlabel=\"Elevation Action\",\n",
        "        ylabel=\"NPV\",\n",
        "        label=\"The NPV for elevating an apartment at different elevations under 10 different SOW's\",\n",
        "        legend=:bottomright,\n",
        "        size=(800, 400),\n",
        "        yformatter=:plain, # prevents scientific notation\n",
        "    )\n",
        "end"
      ],
      "id": "1f98b024",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "let\n",
        "    npv = results\n",
        "    discountrate = [s.discount_rate for s in sows]\n",
        "    scatter(\n",
        "        discountrate,\n",
        "        npv;\n",
        "        xlabel=\"Discount Rate\",\n",
        "        ylabel=\"NPV\",\n",
        "        label=\"The NPV under 10 different SOW's compared to the discount rate (%)\",\n",
        "        legend=:bottomright,\n",
        "        size=(800, 400),\n",
        "        yformatter=:plain, # prevents scientific notation\n",
        "    )\n",
        "end"
      ],
      "id": "38c09348",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "    npv = results\n",
        "    surge = DataFrame(surge_μ=[s.surge_dist.μ for s in sows],\n",
        "    surge_σ=[s.surge_dist.σ for s in sows],\n",
        "    surge_ξ=[s.surge_dist.ξ for s in sows],)\n",
        "    damage = []\n",
        "    for i in 1:110\n",
        "        total = 0\n",
        "        for n in 1:10000\n",
        "            sample = rand(GeneralizedExtremeValue(surge[i, 1], surge[i, 2], surge[i, 3]))\n",
        "            total = total + sample\n",
        "            global dmean = total/10000\n",
        "        end\n",
        "        damage = [damage;dmean]\n",
        "    end\n",
        "    scatter(\n",
        "        damage,\n",
        "        npv;\n",
        "        xlabel=\"Expected flood height from the guage (ft)\",\n",
        "        ylabel=\"NPV\",\n",
        "        label=\"The NPV under 10 different SOW's compared to the expected flood height from the gauge\",\n",
        "        legend=:bottomright,\n",
        "        size=(800, 400),\n",
        "        yformatter=:plain, # prevents scientific notation\n",
        "    )"
      ],
      "id": "75558d0c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Discussion/Analysis\n",
        "\n",
        "Three scatter plots were created to test to what extent the different parameters influenced the final outcome of the NPV. For the analysis, 10 different SOW's were created. Under each of these SOW's 11 actions were performed in each of them by elevating the house from 0 ft to 10 ft. \n",
        "\n",
        "The most important parameter was the elevation action. On the graph, there is a very clear cone of uncertainty with the NPV rising the more you elevate, which makes sense as less money is spent on rebuilding each year.\n",
        "\n",
        "The second most important variable was the expected flood height, which approximates the flood distribution in general. For lower heights, the bulk of the points are near the higher NPV values. As the height increase, however, while you do still find points at high NPV values, they are more spread downwards towards lower NPV values. This makes sense as a lower height will result in lower damages in the future.\n",
        "\n",
        "For the discount rate, there was no meaningful insight that could be gained from the graph as the points were spread out fairly uniformily. I expected higher discount rates to have higher NPV values as costs to rebuild in the future would result in a lower subtraction from the NPV.\n",
        "\n",
        "I couldn't think of a satisfying way to analyze sea rise as unlike the other parameters, it is something that changes throughout the SOW. While the different coefficients in the equation could be graphed, I was unsure what to expect due to my unfamiliarity with the equation.\n",
        "\n",
        "Overall, the analysis shows that it is almost always a good decision to elevate yours house under a range of SOWs. Given unlimited computing power it would make sense to compute many more SOW's and actions as they could better reveal the relationships between the parameters and the NPV. For example, narrowing down on the cone of uncertainty in the NPV vs. Elevation graph. Due to real world computing limitations, though, time to run the program would be the main limiting factor in actually running more SOW's.\n"
      ],
      "id": "a99b33a8"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "julia-1.10",
      "language": "julia",
      "display_name": "Julia 1.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}